{"cells":[{"cell_type":"code","source":["import pandas as pd\n#series = pd.read_csv('/home/cloudera/FeedDB.csv',sep=',',header=None,index_col=0).sort_index()\nimport warnings\nwarnings.filterwarnings(\"ignore\")"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["#x_data = []\n#y_data = []\n \n#for d in range(1,df.shape[0]):\n#    x = df.iloc[d-1:d].values.ravel()\n#    y = df.iloc[d].values[0]\n#    x_data.append(x)\n#    y_data.append(y)"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["#df.head(3)\n#x_data\n#y_data"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["from pandas import Series\nfrom matplotlib import pyplot  as plt\nfrom matplotlib.pylab import rcParams\nrcParams['figure.figsize'] = 15, 6"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["series = Series.from_csv('/home/cloudera/FeedDB_backup.csv',header=None,index_col=0,parse_dates=[0])\nseries.index\nseries.shape[0]\nprint(series.describe())\nplt.plot(series)\n#plt.xticks(rotation='vertical')\nplt.show()\nfrom pandas.tools.plotting import autocorrelation_plot\n\nautocorrelation_plot(series)\nplt.show()"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["series = Series.from_csv('/home/cloudera/FeedDB_backup.csv',header=None,index_col=0,parse_dates=[0])\nseries.index\nseries.shape[0]\nprint(series.describe())\nplt.plot(series)\n#plt.xticks(rotation='vertical')\nplt.show()\nfrom pandas.tools.plotting import autocorrelation_plot\n\nautocorrelation_plot(series)\nplt.show()"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["#transform here for simplicity"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["import numpy as np\nrcParams['figure.figsize'] = 15, 6\nts_log = np.log(series)\n#ts_log.plot()\nplt.plot(ts_log)\nplt.xticks(rotation='vertical')\nplt.show()\nts_log.head(3)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["from statsmodels.tsa.stattools import adfuller\ndef test_stationarity(timeseries,window_size):\n    plt.xticks(rotation='vertical')\n    #Determing rolling statistics\n    rolmean = pd.rolling_mean(timeseries, window=window_size)\n    rolstd = pd.rolling_std(timeseries, window=window_size)\n    plt.show(block=False)\n    \n    #Plot rolling statistics:\n    orig = plt.plot(timeseries, color='blue',label='Original')\n    mean = plt.plot(rolmean, color='red', label='Rolling Mean/Avg')\n    std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n    plt.legend(loc='best')\n    plt.title('Rolling Mean & Standard Deviation')\n    \n    #Perform Dickey-Fuller test:\n    print ('Results of Dickey-Fuller Test:')\n    dftest = adfuller(timeseries, autolag='AIC')\n    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n    for key,value in dftest[4].items():\n        dfoutput['Critical Value (%s)'%key] = value\n    print (dfoutput)"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["#series.head(3)\ntest_stationarity(ts_log,7)"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["#exponentially weighted moving average"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["exp_weighted_avg = pd.ewma(ts_log, halflife= 5)\nplt.plot(ts_log)\nplt.plot(exp_weighted_avg,color='red')\nplt.show()\n"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["ts_log_ewma_diff = ts_log - exp_weighted_avg\ntest_stationarity(ts_log_ewma_diff,7)"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["# decomposing\n"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["# no use\nfrom statsmodels.tsa.seasonal import seasonal_decompose\ndecomposition = seasonal_decompose(ts_log,freq=30)\n\ntrend = decomposition.trend\nseasonal = decomposition.seasonal\nresidual = decomposition.resid\n\nplt.subplot(411)\nplt.plot(ts_log, label='Original')\nplt.legend(loc='best')\nplt.subplot(412)\nplt.plot(trend, label='Trend')\nplt.legend(loc='best')\nplt.subplot(413)\nplt.plot(seasonal,label='Seasonality')\nplt.legend(loc='best')\nplt.subplot(414)\nplt.plot(residual, label='Residuals')\nplt.legend(loc='best')\nplt.tight_layout()\n\nplt.show()"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["ts_log_decompose = residual\nts_log_decompose.dropna(inplace=True)\ntest_stationarity(ts_log_decompose,7)"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["ts_log_diff = ts_log - ts_log.shift()\nplt.plot(ts_log_diff)\nplt.show()"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["'''ARIMA. I won’t go into the technical details but you should understand these concepts in detail if you wish to apply them more effectively. ARIMA stands for Auto-Regressive Integrated Moving Averages. The ARIMA forecasting for a stationary time series is nothing but a linear (like a linear regression) equation. The predictors depend on the parameters (p,d,q) of the ARIMA model:\n\nNumber of AR (Auto-Regressive) terms (p): AR terms are just lags of dependent variable. For instance if p is 5, the predictors for x(t) will be x(t-1)….x(t-5).\nNumber of MA (Moving Average) terms (q): MA terms are lagged forecast errors in prediction equation. For instance if q is 5, the predictors for x(t) will be e(t-1)….e(t-5) where e(i) is the difference between the moving average at ith instant and actual value.\nNumber of Differences (d): These are the number of nonseasonal differences, i.e. in this case we took the first order difference. So either we can pass that variable and put d=0 or pass the original variable and put d=1. Both will generate same results.\n\nAn importance concern here is how to determine the value of ‘p’ and ‘q’. We use two plots to determine these numbers. Lets discuss them first.\n\nAutocorrelation Function (ACF): It is a measure of the correlation between the the TS with a lagged version of itself. For instance at lag 5, ACF would compare series at time instant ‘t1’…’t2’ with series at instant ‘t1-5’…’t2-5’ (t1-5 and t2 being end points).\nPartial Autocorrelation Function (PACF): This measures the correlation between the TS with a lagged version of itself but after eliminating the variations already explained by the intervening comparisons. Eg at lag 5, it will check the correlation but remove the effects already explained by lags 1 to 4.\n\nThe ACF and PACF plots for the TS after differencing can be plotted as:\n'''"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["#ACF and PACF plots:\nfrom statsmodels.tsa.stattools import acf, pacf"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["lag_acf = acf(series, nlags=7)\nlag_pacf = pacf(ts_log_diff, nlags=7, method='ols')"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["plt.plot(lag_acf)\nplt.show()"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["plt.plot(lag_pacf)\nplt.show()"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":23}],"metadata":{"name":"Time_Series_forcasting_testing","notebookId":1392684168636008},"nbformat":4,"nbformat_minor":0}
