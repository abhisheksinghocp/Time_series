{"cells":[{"cell_type":"code","source":["import pandas as pd\nimport numpy as np\nimport matplotlib.pylab as plt\n%matplotlib inline\nfrom matplotlib.pylab import rcParams\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nrcParams['figure.figsize'] = 15, 6"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["data = pd.read_csv('/home/cloudera/FeedDB_backup.csv',sep=',',index_col='day',parse_dates=[0])\nprint(data.info())\nprint ('\\n Data Types:')\nprint (data.dtypes)"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["print(data.shape[0])\nprint(data.index)\ndata.head()\n#data.count"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["# this is final DataTime series (Datatime formart must be yyyy-mm-dd)\nts= data\nprint(ts.describe())\nts['count']['2017-05-02']"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["#from pandas import Series\nfrom matplotlib import pyplot  as plt\nfrom matplotlib.pylab import rcParams\nrcParams['figure.figsize'] = 15, 6"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["plt.plot(ts)\n#plt.xticks(rotation='vertical')\nplt.show()\nfrom pandas.tools.plotting import autocorrelation_plot\nautocorrelation_plot(ts)\nplt.show()"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["#transform here for simplicity"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["'''Dickey-Fuller Test\n\nHow to Check Stationarity of a Time Series?\n'''"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["from statsmodels.tsa.stattools import adfuller\ndef test_stationarity(timeseries,size):\n    print(timeseries.head(5))\n    #Determing rolling statistics\n    rolmean = pd.rolling_mean(timeseries, window=size)\n    rolstd = pd.rolling_std(timeseries, window=size)\n\n    #Plot rolling statistics:\n    orig = plt.plot(timeseries, color='blue',label='Original')\n    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n    std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n    plt.legend(loc='best')\n    plt.title('Rolling Mean & Standard Deviation')\n    plt.show(block=False)\n    \n    #Perform Dickey-Fuller test:\n    print ('Results of Dickey-Fuller Test:')\n    dftest = adfuller(timeseries, autolag='AIC')\n    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n    for key,value in dftest[4].items():\n        dfoutput['Critical Value (%s)'%key] = value\n    print (dfoutput)"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["#series.head(3)\ntest_stationarity(ts['count'],6)"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["'''Note:- VVIP the test statistic is way more than the critical values. Note that the signed values should be compared and not the absolute values.\n\nTS towards stationarity. exponentially weighted moving average\n'''"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["'''Estimating & Eliminating Trend'''"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["ts_log = np.log(ts)\nplt.plot(ts_log)\n# other options are taking a log, square root, cube root, etc"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["'''how to remove trend from data :-some of most commonly used are:\n\nAggregation – taking average for a time period like monthly/weekly averages\nSmoothing – taking rolling averages\nPolynomial Fitting – fit a regression model\n'''"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["#Moving average"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["moving_avg_10 = pd.rolling_mean(ts_log['2017-09-05':],10)\nmoving_avg_7 = pd.rolling_mean(ts_log['2017-09-05':],7)\nmoving_avg_4 = pd.rolling_mean(ts_log['2017-09-05':],4)\nplt.plot(ts_log['2017-09-05':])\nplt.plot(moving_avg_10, color='red')\nplt.plot(moving_avg_7, color='green')\nplt.plot(moving_avg_4, color='black')"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["moving_avg_10 = pd.rolling_mean(ts_log['2017-10-09':],10)\nmoving_avg_7 = pd.rolling_mean(ts_log['2017-10-09':],7)\nmoving_avg_4 = pd.rolling_mean(ts_log['2017-10-09':],4)\nplt.plot(ts_log['2017-11-09':])\nplt.plot(moving_avg_10, color='red')\nplt.plot(moving_avg_7, color='green')\nplt.plot(moving_avg_4, color='black')"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["moving_avg = pd.rolling_mean(ts_log,4)\nplt.plot(ts_log)\nplt.plot(moving_avg, color='red')"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["ts_log_moving_avg_diff.dropna(inplace=True)\ntest_stationarity(ts_log_moving_avg_diff['count'],4)"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["expwighted_avg = pd.ewma(ts_log, halflife=4)\nplt.plot(ts_log)\nplt.plot(expwighted_avg, color='red')"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["ts_log_ewma_diff[ts_log_ewma_diff['count'] == 0].count()"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["ts_log_ewma_diff = ts_log - expwighted_avg\nts_log_ewma_diff.dropna(inplace=True)\nts_log_ewma_diff = ts_log_ewma_diff[ts_log_ewma_diff['count'] < 0]\ntest_stationarity(ts_log_ewma_diff['count'],4)\n#the test statistic is smaller than the 1% critical value, which is better than the previous case."],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["'''Eliminating Trend and Seasonality\n\nThe simple trend reduction techniques discussed before don’t work in all cases, particularly the ones with high seasonality. Lets discuss two ways of removing trend and seasonality:\n\nDifferencing – taking the differece with a particular time lag\nDecomposition – modeling both trend and seasonality and removing them from the model.\n\nDifferencing\n\nOne of the most common methods of dealing with both trend and seasonality is differencing. In this technique, we take the difference of the observation at a particular instant with that at the previous instant. This mostly works well in improving stationarity. First order differencing can be done in Pandas as:\n'''"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["ts_log_diff = ts_log - ts_log.shift()\nplt.plot(ts_log_diff)"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["ts_log_diff.dropna(inplace=True)\ntest_stationarity(ts_log_diff['count'],4)"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["'''Decomposing\n\nIn this approach, both trend and seasonality are modeled separately and the remaining part of the series is returned.\n\nfrom statsmodels.tsa.seasonal import seasonal_decompose decomposition = seasonal_decompose(ts_log,freq=12)\n\ntrend = decomposition.trend seasonal = decomposition.seasonal residual = decomposition.resid\n\nplt.subplot(411) plt.plot(ts_log, label='Original') plt.legend(loc='best') plt.subplot(412) plt.plot(trend, label='Trend') plt.legend(loc='best') plt.subplot(413) plt.plot(seasonal,label='Seasonality') plt.legend(loc='best') plt.subplot(414) plt.plot(residual, label='Residuals') plt.legend(loc='best') plt.tight_layout()\n\nts_log_decompose = residual ts_log_decompose.dropna(inplace=True) test_stationarity(ts_log_decompose,4)\n\nAuto-Regressive Integrated Moving Averages. The ARIMA forecasting for a stationary time series is nothing but a linear (like a linear regression) equation. The predictors depend on the parameters (p,d,q) of the ARIMA model:\n\nThe predictors depend on the parameters (p,d,q) of the ARIMA model:\n\nNumber of AR (Auto-Regressive) terms (p): AR terms are just lags of dependent variable. For instance if p is 5, the predictors for x(t) will be x(t-1)….x(t-5).\nNumber of MA (Moving Average) terms (q): MA terms are lagged forecast errors in prediction equation. For instance if q is 5, the predictors for x(t) will be e(t-1)….e(t-5) where e(i) is the difference between the moving average at ith instant and actual value.\nNumber of Differences (d): These are the number of nonseasonal differences, i.e. in this case we took the first order difference. So either we can pass that variable and put d=0 or pass the original variable and put d=1. Both will generate same results.\n\nAn importance concern here is how to determine the value of ‘p’ and ‘q’. We use two plots to determine these numbers. Lets discuss them first.\n\nAutocorrelation Function (ACF): It is a measure of the correlation between the the TS with a lagged version of itself. For instance at lag 5, ACF would compare series at time instant ‘t1’…’t2’ with series at instant ‘t1-5’…’t2-5’ (t1-5 and t2 being end points).\nPartial Autocorrelation Function (PACF): This measures the correlation between the TS with a lagged version of itself but after eliminating the variations already explained by the intervening comparisons. Eg at lag 5, it will check the correlation but remove the effects already explained by lags 1 to 4.\n\nThe ACF and PACF plots for the TS after differencing can be plotted as:\n'''"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["#ACF and PACF plots:\nfrom statsmodels.tsa.stattools import acf, pacf"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["lag_acf = acf(ts_log_moving_avg_diff, nlags=4)\nlag_pacf = pacf(ts_log_moving_avg_diff, nlags=4, method='ols')"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["plt.subplot(411)\nplt.axhline(y=0,linestyle='--',color='red')\nplt.plot(lag_pacf, label='pacf')\nplt.legend(loc='pacf')\nplt.subplot(412)\nplt.axhline(y=0,linestyle='--',color='red')\nplt.plot(lag_acf, label='acf')\nplt.legend(loc='acf')"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"code","source":["#Plot ACF: \nplt.subplot(121) \nplt.plot(lag_acf)\nplt.axhline(y=0,linestyle='--',color='gray')\nplt.axhline(y=-1.96/np.sqrt(len(ts_log_diff)),linestyle='--',color='gray')\nplt.axhline(y=1.96/np.sqrt(len(ts_log_diff)),linestyle='--',color='gray')\nplt.title('Autocorrelation Function')"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"code","source":["#Plot PACF:\nplt.subplot(122)\nplt.plot(lag_pacf)\nplt.axhline(y=0,linestyle='--',color='gray')\nplt.axhline(y=-1.96/np.sqrt(len(ts_log_diff)),linestyle='--',color='gray')\nplt.axhline(y=1.96/np.sqrt(len(ts_log_diff)),linestyle='--',color='gray')\nplt.title('Partial Autocorrelation Function')\nplt.tight_layout()"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"code","source":["'''p – The lag value where the PACF chart crosses the upper confidence interval for the first time. If you notice closely, in this case p=2.\nq – The lag value where the ACF chart crosses the upper confidence interval for the first time. If you notice closely, in this case q=2.\n\nNow, lets make 3 different ARIMA models considering individual as well as combined effects. I will also print the RSS for each. Please note that here RSS is for the values of residuals and not actual series.\n'''"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"code","source":["#We need to load the ARIMA model first:\nfrom statsmodels.tsa.arima_model import ARIMA\n# The p,d,q values can be specified using the order argument of ARIMA which take a tuple (p,d,q). Let model the 3 cases:"],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"code","source":["#AR Model\nmodel = ARIMA(ts_log_moving_avg_diff, order=(2, 0, 0))  # for this i am getting RSS is Nan order=(2, 1, 0))\nresults_AR = model.fit(disp=0)  \nplt.plot(ts_log_moving_avg_diff)\nplt.plot(results_AR.fittedvalues, color='red')\nplt.title('RSS: %.4f'% sum((results_AR.fittedvalues-ts_log_moving_avg_diff['count'])**2))\nresults_AR.summary()"],"metadata":{},"outputs":[],"execution_count":34},{"cell_type":"code","source":["#MA Model\n\nmodel = ARIMA(ts_log_moving_avg_diff, order=(0, 0, 2))  \nresults_MA = model.fit(disp=-1)  \nplt.plot(ts_log_moving_avg_diff)\nplt.plot(results_MA.fittedvalues, color='red')\nplt.title('RSS: %.4f'% sum((results_MA.fittedvalues-ts_log_moving_avg_diff['count'])**2))"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"code","source":["#Combined Model\nmodel = ARIMA(ts_log_moving_avg_diff, order=(2, 0, 2))  \nresults_ARIMA = model.fit(disp=-1)  \nplt.plot(ts_log_moving_avg_diff)\nplt.plot(results_ARIMA.fittedvalues, color='red')\nplt.title('RSS: %.4f'% sum((results_ARIMA.fittedvalues-ts_log_moving_avg_diff['count'])**2))"],"metadata":{},"outputs":[],"execution_count":36},{"cell_type":"code","source":["# plot residual\nresidual = pd.DataFrame(results_ARIMA.resid)\nresidual.plot()\nplt.show()"],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"code","source":["residual.plot(kind='kde')\nplt.show()\nprint(residual.describe())"],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"code","source":["predictions_ARIMA_diff = pd.Series(results_ARIMA.fittedvalues, copy=True)\nprint (predictions_ARIMA_diff.head())\nplt.plot(ts_log_diff)\nplt.plot(predictions_ARIMA_diff, color='red')"],"metadata":{},"outputs":[],"execution_count":39},{"cell_type":"code","source":["#The way to convert the differencing to log scale is to add these differences consecutively to the base number. \n#An easy way to do it is to first determine the cumulative sum at index and then add it to the base number. \n#The cumulative sum can be found as:\n\npredictions_ARIMA_diff_cumsum = predictions_ARIMA_diff.cumsum()\nprint (predictions_ARIMA_diff_cumsum.head())"],"metadata":{},"outputs":[],"execution_count":40},{"cell_type":"code","source":["predictions_ARIMA_log = pd.Series(ts_log.ix[0], index=ts_log.index)\npredictions_ARIMA_log = predictions_ARIMA_log.add(predictions_ARIMA_diff_cumsum,fill_value=0)\npredictions_ARIMA_log.head()"],"metadata":{},"outputs":[],"execution_count":41},{"cell_type":"code","source":["predictions_ARIMA = np.exp(predictions_ARIMA_log)\nplt.plot(ts)\nplt.plot(predictions_ARIMA)\n#plt.title('RMSE: %.4f'% np.sqrt(sum((predictions_ARIMA-ts)**2)/len(ts)))"],"metadata":{},"outputs":[],"execution_count":42},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":43}],"metadata":{"name":"Time_Series_forcasting-Working","notebookId":1392684168636033},"nbformat":4,"nbformat_minor":0}
